# ModelScope API Gateway

ModelScope é­”æ­ç¤¾åŒº API è´Ÿè½½å‡è¡¡ç½‘å…³ï¼Œæ”¯æŒå¤šæ¨¡å‹è‡ªåŠ¨åˆ‡æ¢ã€æ™ºèƒ½è·¯ç”±ã€é…é¢ç®¡ç†ã€‚

## âœ¨ ç‰¹æ€§

- **è´Ÿè½½å‡è¡¡** - æŒ‰ä¼˜å…ˆçº§è‡ªåŠ¨é€‰æ‹©å¯ç”¨æ¨¡å‹ï¼Œå•ä¸ªæ¨¡å‹é…é¢ç”¨å°½è‡ªåŠ¨åˆ‡æ¢
- **æ™ºèƒ½è·¯ç”±** - é€šè¿‡æœ¬åœ° AI åˆ†æä»»åŠ¡å¤æ‚åº¦ï¼Œè‡ªåŠ¨åˆ†é…åˆ°åˆé€‚çš„æ¨¡å‹å±‚çº§
- **é…é¢è¿½è¸ª** - è‡ªåŠ¨ä» API å“åº”å¤´è·å–é…é¢ä¿¡æ¯ï¼Œè®°å½•æ¯æ—¥ä½¿ç”¨é‡
- **é”™è¯¯é‡è¯•** - é‡åˆ° 401/429 é”™è¯¯è‡ªåŠ¨åˆ‡æ¢æ¨¡å‹é‡è¯•
- **OpenAI å…¼å®¹** - æä¾› `/v1/chat/completions` æ¥å£ï¼Œå…¼å®¹ OpenAI SDK
- **Docker éƒ¨ç½²** - æä¾›å®Œæ•´çš„ Docker å’Œ Docker Compose é…ç½®

## ğŸ“¦ å®‰è£…

### æœ¬åœ°å®‰è£…

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/lascyb/modelscope.git
cd modelscope

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰
python -m venv .venv
.venv\Scripts\activate  # Windows
# source .venv/bin/activate  # Linux/Mac

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# é…ç½®ç¯å¢ƒå˜é‡
cp env.example .env
# ç¼–è¾‘ .env å¡«å…¥ MODELSCOPE_API_KEY
```

### Docker éƒ¨ç½²

```bash
# é…ç½®ç¯å¢ƒå˜é‡
cp env.example .env
# ç¼–è¾‘ .env å¡«å…¥ MODELSCOPE_API_KEY

# å¯åŠ¨æœåŠ¡
docker-compose --env-file .env -f deploy/docker-compose.yml up -d

# æŸ¥çœ‹æ—¥å¿—
docker-compose -f deploy/docker-compose.yml logs -f
```

## ğŸš€ å¯åŠ¨

### å‘½ä»¤è¡Œå¯åŠ¨

```bash
python server.py
```

æˆ–ä½¿ç”¨ uvicornï¼š

```bash
uvicorn server:app --host 0.0.0.0 --port 8000 --reload
```

### è®¿é—® API æ–‡æ¡£

å¯åŠ¨åè®¿é—®ï¼šhttp://localhost:8000/docs

## ğŸ“– API æ¥å£

### OpenAI å…¼å®¹æ¥å£

| ç«¯ç‚¹ | æ–¹æ³• | è¯´æ˜ |
|------|------|------|
| `/v1/chat/completions` | POST | èŠå¤©è¡¥å…¨ï¼ˆæ”¯æŒæµå¼ï¼‰ |
| `/v1/models` | GET | æ¨¡å‹åˆ—è¡¨ |
| `/v1/models/{model_id}` | GET | æ¨¡å‹è¯¦æƒ… |

**ä½¿ç”¨ OpenAI SDKï¼š**

```python
from openai import OpenAI

client = OpenAI(
    base_url="http://localhost:8000/v1",
    api_key="any"  # æœ¬åœ°æœåŠ¡å¯å¡«ä»»æ„å€¼
)

response = client.chat.completions.create(
    model="auto",  # è‡ªåŠ¨é€‰æ‹©æ¨¡å‹
    messages=[{"role": "user", "content": "ä½ å¥½"}],
)
print(response.choices[0].message.content)
```

**ä½¿ç”¨ curlï¼š**

```bash
curl http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [{"role": "user", "content": "ä½ å¥½"}],
    "stream": false
  }'
```

### åŸç”Ÿæ¥å£

| ç«¯ç‚¹ | æ–¹æ³• | è¯´æ˜ |
|------|------|------|
| `/chat` | POST | èŠå¤©æ¥å£ï¼ˆæ›´å¤šæ§åˆ¶é€‰é¡¹ï¼‰ |
| `/status` | GET | ä½¿ç”¨çŠ¶æ€å’Œé…é¢ä¿¡æ¯ |
| `/models` | GET | æ¨¡å‹åˆ—è¡¨ |
| `/reload` | POST | é‡æ–°åŠ è½½é…ç½® |
| `/n8n/chat` | POST | n8n ä¸“ç”¨ç®€åŒ–æ¥å£ |

**èŠå¤©è¯·æ±‚ç¤ºä¾‹ï¼š**

```json
{
  "messages": [
    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹"},
    {"role": "user", "content": "ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"}
  ],
  "stream": false,
  "smart_route": true,
  "max_tokens": 500
}
```

## âš™ï¸ é…ç½®

### ç¯å¢ƒå˜é‡ (.env)

```env
# ModelScope API å¯†é’¥ï¼ˆå¿…å¡«ï¼‰
MODELSCOPE_API_KEY=your-api-key-here

# æœåŠ¡å™¨é…ç½®
SERVER_HOST=0.0.0.0
SERVER_PORT=8000

# æœ¬åœ° AI é…ç½®ï¼ˆæ™ºèƒ½è·¯ç”±ï¼Œå¯é€‰ï¼‰
LOCAL_AI_BASE_URL=http://localhost:11434
LOCAL_AI_MODEL=qwen2.5:1.5b
```

### æ¨¡å‹é…ç½® (models_config.json)

```json
{
  "models": [
    {
      "id": "deepseek-ai/DeepSeek-R1-0528",
      "name": "DeepSeek-R1",
      "tier": 1,
      "enabled": true
    },
    {
      "id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "name": "Qwen3-235B",
      "tier": 2,
      "enabled": true
    }
  ],
  "smart_routing": {
    "enabled": true,
    "local_ai": {
      "base_url": "http://localhost:11434",
      "model": "qwen2.5:1.5b"
    }
  }
}
```

**é…ç½®è¯´æ˜ï¼š**

- `id` - ModelScope æ¨¡å‹ ID
- `name` - æ˜¾ç¤ºåç§°
- `tier` - æ¨¡å‹å±‚çº§ï¼ˆ1=æœ€å¼ºï¼Œ4=æœ€è½»é‡ï¼‰
- `enabled` - æ˜¯å¦å¯ç”¨
- æ¨¡å‹é¡ºåºå†³å®šä¼˜å…ˆçº§ï¼ˆè¶Šé å‰ä¼˜å…ˆçº§è¶Šé«˜ï¼‰

## ğŸ§  æ™ºèƒ½è·¯ç”±

æ™ºèƒ½è·¯ç”±ä½¿ç”¨æœ¬åœ° AIï¼ˆå¦‚ Ollamaï¼‰åˆ†æä»»åŠ¡å¤æ‚åº¦ï¼Œè‡ªåŠ¨é€‰æ‹©åˆé€‚çš„æ¨¡å‹ï¼š

| å¤æ‚åº¦ | åˆ†æ•° | æ¨¡å‹å±‚çº§ | ç¤ºä¾‹ä»»åŠ¡ |
|--------|------|----------|----------|
| ç®€å• | 1-3 | Tier 4 | æ‰“æ‹›å‘¼ã€ç®€å•é—®ç­” |
| ä¸­ç­‰ | 4-5 | Tier 3 | è§£é‡Šæ¦‚å¿µã€æ‘˜è¦ |
| å¤æ‚ | 6-7 | Tier 2 | ä»£ç ç¼–å†™ã€åˆ†æ |
| éå¸¸å¤æ‚ | 8-10 | Tier 1 | æ•°å­¦æ¨ç†ã€ç³»ç»Ÿè®¾è®¡ |

### å¯ç”¨æ™ºèƒ½è·¯ç”±

1. å®‰è£… Ollama: https://ollama.com
2. ä¸‹è½½æ¨¡å‹ï¼š`ollama pull qwen2.5:1.5b`
3. ç¡®ä¿ `models_config.json` ä¸­ `smart_routing.enabled` ä¸º `true`

## ğŸ“ ç›®å½•ç»“æ„

```
modelscope/
â”œâ”€â”€ core/                        # æ ¸å¿ƒæ¨¡å—
â”‚   â”œâ”€â”€ __init__.py              # åŒ…åˆå§‹åŒ–
â”‚   â”œâ”€â”€ api_client.py            # API å®¢æˆ·ç«¯
â”‚   â”œâ”€â”€ load_balancer.py         # è´Ÿè½½å‡è¡¡å™¨
â”‚   â”œâ”€â”€ limits_tracker.py        # é…é¢è¿½è¸ªå™¨
â”‚   â”œâ”€â”€ usage_tracker.py         # ä½¿ç”¨é‡è¿½è¸ªå™¨
â”‚   â””â”€â”€ task_analyzer.py         # ä»»åŠ¡åˆ†æå™¨
â”œâ”€â”€ deploy/                      # éƒ¨ç½²é…ç½®
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ docker-compose.yml       # ç”Ÿäº§ç¯å¢ƒ
â”‚   â””â”€â”€ docker-compose.dev.yml   # å¼€å‘ç¯å¢ƒ
â”œâ”€â”€ usage/                       # ä½¿ç”¨é‡è®°å½• (YYYY-MM-DD.json)
â”œâ”€â”€ limits/                      # é…é¢è®°å½• (YYYY-MM-DD.json)
â”œâ”€â”€ server.py                    # HTTP æœåŠ¡å…¥å£
â”œâ”€â”€ main.py                      # å‘½ä»¤è¡Œç¤ºä¾‹
â”œâ”€â”€ models_config.json           # æ¨¡å‹é…ç½®
â”œâ”€â”€ env.example                  # ç¯å¢ƒå˜é‡æ¨¡æ¿
â””â”€â”€ requirements.txt             # Python ä¾èµ–
```

## ğŸ”§ Python SDK ä½¿ç”¨

```python
from core import ModelScopeClient

# åˆ›å»ºå®¢æˆ·ç«¯
client = ModelScopeClient(api_key="your-api-key")

# å‘é€èŠå¤©è¯·æ±‚
response = client.chat(
    messages=[{"role": "user", "content": "ä½ å¥½"}],
    smart_route=True,  # å¯ç”¨æ™ºèƒ½è·¯ç”±
)

print(f"æ¨¡å‹: {response['model']}")
print(f"å›å¤: {response['content']}")

# è·å–çŠ¶æ€
status = client.get_status()
print(f"ä»Šæ—¥ä½¿ç”¨: {status['total_usage']}")
print(f"å‰©ä½™é…é¢: {status['remaining']}")
```

## ğŸ“Š é…é¢è¯´æ˜

ModelScope é­”æ­ç¤¾åŒºæä¾›ï¼š

- **å…¨å±€é™åˆ¶**: æ¯äººæ¯å¤© 2000 æ¬¡ API è°ƒç”¨
- **æ¨¡å‹é™åˆ¶**: æ¯ä¸ªæ¨¡å‹æœ‰å„è‡ªçš„æ¯æ—¥é™åˆ¶

æœ¬ç½‘å…³è‡ªåŠ¨ä» API å“åº”å¤´è·å–é…é¢ä¿¡æ¯ï¼š

| å“åº”å¤´ | è¯´æ˜ |
|--------|------|
| `modelscope-ratelimit-requests-limit` | ç”¨æˆ·å½“å¤©é™é¢ |
| `modelscope-ratelimit-requests-remaining` | ç”¨æˆ·å½“å¤©å‰©ä½™ |
| `modelscope-ratelimit-model-requests-limit` | æ¨¡å‹å½“å¤©é™é¢ |
| `modelscope-ratelimit-model-requests-remaining` | æ¨¡å‹å½“å¤©å‰©ä½™ |

## ğŸ³ Docker

### ç”Ÿäº§ç¯å¢ƒ

```bash
docker-compose --env-file .env -f deploy/docker-compose.yml up -d
```

### å¼€å‘ç¯å¢ƒï¼ˆçƒ­é‡è½½ï¼‰

```bash
docker-compose --env-file .env -f deploy/docker-compose.dev.yml up
```

### å¯ç”¨ Ollamaï¼ˆæ™ºèƒ½è·¯ç”±ï¼‰

```bash
docker-compose --env-file .env -f deploy/docker-compose.yml --profile with-ollama up -d
```

## ğŸ“ License

[Apache License 2.0](LICENSE)
